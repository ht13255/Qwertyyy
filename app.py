import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import noisereduce as nr
import pandas as pd
from transformers import AutoModelForAudioClassification, AutoFeatureExtractor
import subprocess
import os
import imageio_ffmpeg as ffmpeg
import torch
import torchaudio
from io import StringIO


# í‰ê°€ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def grade(score):
    if score >= 95:
        return "A+"
    elif score >= 90:
        return "A"
    elif score >= 85:
        return "B+"
    elif score >= 80:
        return "B"
    elif score >= 75:
        return "C+"
    elif score >= 70:
        return "C"
    elif score >= 65:
        return "D+"
    elif score >= 60:
        return "D"
    elif score >= 50:
        return "F+"
    else:
        return "F-"


# Hzë¥¼ ì˜¥íƒ€ë¸Œì™€ ìŒê³„ë¡œ ë³€í™˜
def hz_to_note_name(hz):
    if hz <= 0:
        return "Unknown"
    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    midi_number = round(12 * np.log2(hz / 440.0) + 69)
    note = note_names[midi_number % 12]
    octave = (midi_number // 12) - 1
    return f"{octave}ì˜¥íƒ€ë¸Œ {note}"


# ìŒëŸ‰ ì¡°ì • í•¨ìˆ˜
def adjust_volume(y, target_rms=0.1):
    current_rms = np.sqrt(np.mean(y ** 2))
    adjustment_factor = target_rms / (current_rms + 1e-6)
    return y * adjustment_factor


# Hz í¬ê¸° ì¡°ì • í•¨ìˆ˜
def scale_hz(y, sr, target_pitch=440.0):
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    valid_pitches = pitches[pitches > 0]
    if len(valid_pitches) > 0:
        mean_pitch = np.mean(valid_pitches)
        scaling_factor = target_pitch / mean_pitch
        return librosa.effects.time_stretch(y, rate=scaling_factor)
    return y


# ì˜¤ë””ì˜¤ ë°ì´í„° í´ë¦¬ë‹ í•¨ìˆ˜
def clean_audio(y):
    """
    NaN ë˜ëŠ” Infinity ê°’ì„ ì œê±°í•˜ê³  í´ë¦¬ë‹ëœ ì˜¤ë””ì˜¤ ë°ì´í„°ë¥¼ ë°˜í™˜.
    """
    if not np.all(np.isfinite(y)):  # NaN ë˜ëŠ” Infinityê°€ ìˆëŠ”ì§€ í™•ì¸
        y = np.nan_to_num(y)  # NaNì€ 0ìœ¼ë¡œ, InfinityëŠ” í° ìœ í•œ ê°’ìœ¼ë¡œ ë³€í™˜
    return y


# ì—…ë¡œë“œëœ ìŒì„±ì„ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
def convert_to_wav(uploaded_file, output_path="temp_audio.wav"):
    ffmpeg_path = ffmpeg.get_ffmpeg_exe()
    with open("temp_input_file", "wb") as f:
        f.write(uploaded_file.read())
    try:
        subprocess.run(
            [ffmpeg_path, "-y", "-i", "temp_input_file", output_path],
            check=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        return output_path
    except Exception as e:
        st.error(f"íŒŒì¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


# Hugging Face ëª¨ë¸ ë° ì²˜ë¦¬ê¸° ë¡œë“œ
def load_audio_model():
    model_name = "superb/hubert-large-superb-er"
    try:
        feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)
        model = AutoModelForAudioClassification.from_pretrained(model_name)
        return feature_extractor, model
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, None


# Streamlit ì œëª©
st.title("ğŸ¤ AI ê¸°ë°˜ ìŒì„± ë¶„ì„ ë° ì¥ë¥´ ì í•©ì„± í‰ê°€")

# ì‚¬ìš©ì ì…ë ¥
target_genre = st.text_input("ë¶„ì„í•  ë…¸ë˜ ì¥ë¥´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: Pop, Jazz, Rock)", value="Pop")

# ìŒì„± íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ìŒì„±ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (MP3, AAC, OGG, WAV ë“± ì§€ì›)", type=["mp3", "wav", "ogg", "aac", "wma"])

if uploaded_file:
    try:
        st.audio(uploaded_file, format="audio/wav")
        st.write("ì—…ë¡œë“œëœ ìŒì„±ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")

        # íŒŒì¼ ë³€í™˜
        wav_path = convert_to_wav(uploaded_file)
        if not wav_path:
            st.error("íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨ë¡œ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            st.stop()

        # 1ï¸âƒ£ ìŒì„± ë¡œë“œ
        y, sr = librosa.load(wav_path, sr=None)
        y = clean_audio(y)  # NaN ë˜ëŠ” Infinity ê°’ ì œê±°
        st.write("âœ… ìŒì„± íŒŒì¼ ë¡œë“œ ì™„ë£Œ.")

        # 2ï¸âƒ£ ìŒëŸ‰ ìë™ ì¡°ì •
        adjusted_y = adjust_volume(y)
        st.write("âœ… ìŒëŸ‰ ì¡°ì • ì™„ë£Œ.")

        # 3ï¸âƒ£ Hz í¬ê¸° ìë™ ì¡°ì •
        scaled_y = scale_hz(adjusted_y, sr, target_pitch=440.0)
        scaled_y = clean_audio(scaled_y)  # ë‹¤ì‹œ í´ë¦¬ë‹
        st.write("âœ… Hz í¬ê¸° ì¡°ì • ì™„ë£Œ.")

        # 4ï¸âƒ£ ë…¸ì´ì¦ˆ ì œê±°
        reduced_noise = nr.reduce_noise(y=scaled_y, sr=sr, prop_decrease=0.8)
        reduced_noise = clean_audio(reduced_noise)  # ë‹¤ì‹œ í´ë¦¬ë‹
        st.write("âœ… ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ.")

        # ë‚˜ë¨¸ì§€ ë¶„ì„ ê³¼ì •...
        st.success("ğŸ‰ ë¶„ì„ ë° ê°œì„  ì‚¬í•­ ì œì•ˆì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")