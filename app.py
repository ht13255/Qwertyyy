import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import noisereduce as nr
import pandas as pd
from transformers import AutoModelForAudioClassification, AutoFeatureExtractor
import subprocess
import os
import imageio_ffmpeg as ffmpeg
import torch
import torchaudio
from io import StringIO


# í‰ê°€ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def grade(score):
    if score >= 95:
        return "A+"
    elif score >= 90:
        return "A"
    elif score >= 85:
        return "B+"
    elif score >= 80:
        return "B"
    elif score >= 75:
        return "C+"
    elif score >= 70:
        return "C"
    elif score >= 65:
        return "D+"
    elif score >= 60:
        return "D"
    elif score >= 50:
        return "F+"
    else:
        return "F-"


# Hzë¥¼ ì˜¥íƒ€ë¸Œì™€ ìŒê³„ë¡œ ë³€í™˜
def hz_to_note_name(hz):
    if hz <= 0:
        return "Unknown"
    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    midi_number = round(12 * np.log2(hz / 440.0) + 69)
    note = note_names[midi_number % 12]
    octave = (midi_number // 12) - 1
    return f"{octave}ì˜¥íƒ€ë¸Œ {note}"


# ì§€ì§€ìŒì—­ ê³„ì‚° í•¨ìˆ˜
def calculate_supported_range(valid_pitches, stability_threshold=0.8):
    min_pitch = np.min(valid_pitches)
    max_pitch = np.max(valid_pitches)
    supported_min = min_pitch * stability_threshold
    supported_max = max_pitch * stability_threshold
    return supported_min, supported_max


# ìŒëŸ‰ ì¡°ì • í•¨ìˆ˜
def adjust_volume(y, target_rms=0.1):
    current_rms = np.sqrt(np.mean(y ** 2))
    adjustment_factor = target_rms / (current_rms + 1e-6)
    return y * adjustment_factor


# Hz í¬ê¸° ì¡°ì • í•¨ìˆ˜
def scale_hz(y, sr, target_pitch=440.0):
    pitches, magnitudes = librosa.piptrack(y=y, sr=sr)
    valid_pitches = pitches[pitches > 0]
    if len(valid_pitches) > 0:
        mean_pitch = np.mean(valid_pitches)
        scaling_factor = target_pitch / mean_pitch
        return librosa.effects.time_stretch(y, rate=scaling_factor)
    return y


# ì—…ë¡œë“œëœ ìŒì„±ì„ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
def convert_to_wav(uploaded_file, output_path="temp_audio.wav"):
    ffmpeg_path = ffmpeg.get_ffmpeg_exe()
    with open("temp_input_file", "wb") as f:
        f.write(uploaded_file.read())
    try:
        subprocess.run(
            [ffmpeg_path, "-y", "-i", "temp_input_file", output_path],
            check=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        return output_path
    except Exception as e:
        st.error(f"íŒŒì¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


# Hugging Face ëª¨ë¸ ë° ì²˜ë¦¬ê¸° ë¡œë“œ
def load_audio_model():
    model_name = "superb/hubert-large-superb-er"
    try:
        feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)
        model = AutoModelForAudioClassification.from_pretrained(model_name)
        return feature_extractor, model
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None, None


# ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¥ë¥´ì™€ ì¼ì¹˜ë„ í‰ê°€
def evaluate_genre(target_genre, predicted_genre):
    return 100 if target_genre.lower() == predicted_genre.lower() else 50


# ë³´ì»¬ ì‹¤ë ¥ í‰ê°€ (AI ê¸°ë°˜)
def evaluate_vocal_skill(file_path, feature_extractor, model):
    try:
        waveform, sample_rate = torchaudio.load(file_path)
        inputs = feature_extractor(waveform, sampling_rate=sample_rate, return_tensors="pt", padding=True)
        with torch.no_grad():
            logits = model(**inputs).logits
        confidence_score = torch.max(torch.softmax(logits, dim=-1)).item() * 100
        return confidence_score
    except Exception as e:
        st.error(f"ë³´ì»¬ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return 0


# Streamlit ì œëª©
st.title("ğŸ¤ AI ê¸°ë°˜ ìŒì„± ë¶„ì„ ë° ì§€ì§€ìŒì—­ í‰ê°€")

# ì‚¬ìš©ì ì…ë ¥
target_genre = st.text_input("ë¶„ì„í•  ë…¸ë˜ ì¥ë¥´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: Pop, Jazz, Rock)", value="Pop")

# ìŒì„± íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ìŒì„±ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (MP3, AAC, OGG, WAV ë“± ì§€ì›)", type=["mp3", "wav", "ogg", "aac", "wma"])

if uploaded_file:
    try:
        st.audio(uploaded_file, format="audio/wav")
        st.write("ì—…ë¡œë“œëœ ìŒì„±ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")

        # íŒŒì¼ ë³€í™˜
        wav_path = convert_to_wav(uploaded_file)
        if not wav_path:
            st.error("íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨ë¡œ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            st.stop()

        # 1ï¸âƒ£ ìŒì„± ë¡œë“œ
        y, sr = librosa.load(wav_path, sr=None)
        st.write("âœ… ìŒì„± íŒŒì¼ ë¡œë“œ ì™„ë£Œ.")

        # 2ï¸âƒ£ ìŒëŸ‰ ìë™ ì¡°ì •
        adjusted_y = adjust_volume(y)
        st.write("âœ… ìŒëŸ‰ ì¡°ì • ì™„ë£Œ.")

        # 3ï¸âƒ£ Hz í¬ê¸° ìë™ ì¡°ì •
        scaled_y = scale_hz(adjusted_y, sr, target_pitch=440.0)
        st.write("âœ… Hz í¬ê¸° ì¡°ì • ì™„ë£Œ.")

        # 4ï¸âƒ£ ë…¸ì´ì¦ˆ ì œê±°
        reduced_noise = nr.reduce_noise(y=scaled_y, sr=sr, prop_decrease=0.8)
        st.write("âœ… ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ.")

        # 5ï¸âƒ£ ìŒì—­ëŒ€ ë¶„ì„
        pitches, magnitudes = librosa.piptrack(y=reduced_noise, sr=sr)
        valid_pitches = pitches[pitches > 0]
        min_pitch = np.min(valid_pitches)
        max_pitch = np.max(valid_pitches)
        mean_pitch = np.mean(valid_pitches)

        # ì˜¥íƒ€ë¸Œ ë° ìŒê³„ ê³„ì‚°
        min_note = hz_to_note_name(min_pitch)
        max_note = hz_to_note_name(max_pitch)
        mean_note = hz_to_note_name(mean_pitch)

        # ì§€ì§€ìŒì—­ ê³„ì‚°
        supported_min, supported_max = calculate_supported_range(valid_pitches)
        supported_min_note = hz_to_note_name(supported_min)
        supported_max_note = hz_to_note_name(supported_max)

        # 6ï¸âƒ£ AI ë¶„ì„
        feature_extractor, model = load_audio_model()
        if feature_extractor and model:
            predicted_genre = "Pop"  # AI ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©í•  ê²½ìš° ìˆ˜ì • ê°€ëŠ¥
            genre_score = evaluate_genre(target_genre, predicted_genre)
            vocal_skill_score = evaluate_vocal_skill(wav_path, feature_extractor, model)
        else:
            predicted_genre = "ë¶„ì„ ì‹¤íŒ¨"
            genre_score = 0
            vocal_skill_score = 0

        # ë“±ê¸‰ ê³„ì‚°
        genre_grade = grade(genre_score)
        vocal_grade = grade(vocal_skill_score)

        # ê²°ê³¼ ì¶œë ¥
        st.subheader("ğŸ¤ ë¶„ì„ ê²°ê³¼")
        st.write(f"ì…ë ¥í•œ ì¥ë¥´: {target_genre}")
        st.write(f"AI ë¶„ì„ ì¥ë¥´: {predicted_genre}")
        st.write(f"ì¥ë¥´ ì í•©ì„± ì ìˆ˜: {genre_score}ì  ({genre_grade})")
        st.write(f"ë³´ì»¬ ì‹¤ë ¥ ì ìˆ˜: {vocal_skill_score:.2f}ì  ({vocal_grade})")
        st.write(f"ìµœì†Œ ìŒì—­: {min_pitch:.2f} Hz ({min_note})")
        st.write(f"ìµœëŒ€ ìŒì—­: {max_pitch:.2f} Hz ({max_note})")
        st.write(f"í‰ê·  ìŒì—­: {mean_pitch:.2f} Hz ({mean_note})")
        st.write(f"ì§€ì§€ ìŒì—­: {supported_min:.2f} Hz ({supported_min_note}) ~ {supported_max:.2f} Hz ({supported_max_note})")

        # ê²°ê³¼ ì €ì¥ ê¸°ëŠ¥
        csv_buffer = StringIO()
        results = {
            "ì…ë ¥í•œ ì¥ë¥´": [target_genre],
            "AI ë¶„ì„ ì¥ë¥´": [predicted_genre],
            "ì¥ë¥´ ì í•©ì„± ì ìˆ˜": [genre_score],
            "ì¥ë¥´ ì í•©ì„± ë“±ê¸‰": [genre_grade],
            "ë³´ì»¬ ì‹¤ë ¥ ì ìˆ˜": [vocal_skill_score],
            "ë³´ì»¬ ì‹¤ë ¥ ë“±ê¸‰": [vocal_grade],
            "ìµœì†Œ ìŒì—­ (Hz)": [min_pitch],
            "ìµœì†Œ ìŒì—­ (ìŒê³„)": [min_note],
            "ìµœëŒ€ ìŒì—­ (Hz)": [max_pitch],
            "ìµœëŒ€ ìŒì—­ (ìŒê³„)": [max_note],
            "í‰ê·  ìŒì—­ (Hz)": [mean_pitch],
            "í‰ê·  ìŒì—­ (ìŒê³„)": [mean_note],
            "ì§€ì§€ ìŒì—­ (Hz)": [f"{supported_min:.2f} ~ {supported_max:.2f}"],
            "ì§€ì§€ ìŒì—­ (ìŒê³„)": [f"{supported_min_note} ~ {supported_max_note}"],
        }
        df_results = pd.DataFrame(results)
        df_results.to_csv(csv_buffer, index=False, encoding='utf-8-sig')
        st.download_button(
            label="ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥",
            data=csv_buffer.getvalue(),
            file_name="ìŒì„±_ë¶„ì„_ê²°ê³¼.csv",
            mime="text/csv"
        )

        st.success("ğŸ‰ ë¶„ì„ ë° ê°œì„  ì‚¬í•­ ì œì•ˆì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
