import streamlit as st
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import noisereduce as nr
import pandas as pd
from transformers import AutoModelForAudioClassification, AutoFeatureExtractor
import subprocess
import os
import imageio_ffmpeg as ffmpeg
import torch
import torchaudio
from io import StringIO


# í‰ê°€ ì ìˆ˜ ê³„ì‚° í•¨ìˆ˜
def grade(score):
    if score >= 95:
        return "A+"
    elif score >= 90:
        return "A"
    elif score >= 85:
        return "B+"
    elif score >= 80:
        return "B"
    elif score >= 75:
        return "C+"
    elif score >= 70:
        return "C"
    elif score >= 65:
        return "D+"
    elif score >= 60:
        return "D"
    elif score >= 50:
        return "F+"
    else:
        return "F-"


# Hzë¥¼ ì˜¥íƒ€ë¸Œì™€ ìŒê³„ë¡œ ë³€í™˜
def hz_to_note_name(hz):
    if hz <= 0:
        return "Unknown"
    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    midi_number = round(12 * np.log2(hz / 440.0) + 69)
    note = note_names[midi_number % 12]
    octave = (midi_number // 12) - 1
    return f"{octave}ì˜¥íƒ€ë¸Œ {note}"


# ìŒëŸ‰ ì¡°ì • í•¨ìˆ˜
def adjust_volume(y, target_rms=0.1):
    current_rms = np.sqrt(np.mean(y ** 2))
    adjustment_factor = target_rms / (current_rms + 1e-6)
    return y * adjustment_factor


# ì—…ë¡œë“œëœ ìŒì„±ì„ WAV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
def convert_to_wav(uploaded_file, output_path="temp_audio.wav"):
    ffmpeg_path = ffmpeg.get_ffmpeg_exe()
    with open("temp_input_file", "wb") as f:
        f.write(uploaded_file.read())
    try:
        subprocess.run(
            [ffmpeg_path, "-y", "-i", "temp_input_file", output_path],
            check=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        return output_path
    except Exception as e:
        st.error(f"íŒŒì¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None


# Streamlit ì œëª©
st.title("ğŸ¤ ë‹¤ì–‘í•œ ìŒì„± íŒŒì¼ ë¶„ì„ ë° ìŒëŸ‰ ì¡°ì •")

# ìŒì„± íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ìŒì„±ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (MP3, AAC, OGG, WAV ë“± ì§€ì›)", type=["mp3", "wav", "ogg", "aac", "wma"])

if uploaded_file:
    try:
        st.audio(uploaded_file, format="audio/wav")
        st.write("ì—…ë¡œë“œëœ ìŒì„±ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")

        # íŒŒì¼ ë³€í™˜
        wav_path = convert_to_wav(uploaded_file)
        if not wav_path:
            st.error("íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨ë¡œ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            st.stop()

        # 1ï¸âƒ£ ìŒì„± ë¡œë“œ
        y, sr = librosa.load(wav_path, sr=None)
        st.write("âœ… ìŒì„± íŒŒì¼ ë¡œë“œ ì™„ë£Œ.")

        # 2ï¸âƒ£ ìŒëŸ‰ ì¡°ì •
        adjusted_y = adjust_volume(y)
        st.write("âœ… ìŒëŸ‰ ì¡°ì • ì™„ë£Œ.")

        # 3ï¸âƒ£ ë…¸ì´ì¦ˆ ì œê±°
        reduced_noise = nr.reduce_noise(y=adjusted_y, sr=sr, prop_decrease=0.8)
        st.write("âœ… ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ.")

        # 4ï¸âƒ£ ìŒì—­ëŒ€ ë¶„ì„
        pitches, magnitudes = librosa.piptrack(y=reduced_noise, sr=sr)
        valid_pitches = pitches[pitches > 0]
        min_pitch = np.min(valid_pitches)
        max_pitch = np.max(valid_pitches)
        mean_pitch = np.mean(valid_pitches)

        # ì˜¥íƒ€ë¸Œ ë° ìŒê³„ ê³„ì‚°
        min_note = hz_to_note_name(min_pitch)
        max_note = hz_to_note_name(max_pitch)
        mean_note = hz_to_note_name(mean_pitch)

        # ê²°ê³¼ ì¶œë ¥
        st.subheader("ğŸ¤ ë¶„ì„ ê²°ê³¼")
        st.write(f"ìµœì†Œ ìŒì—­: {min_pitch:.2f} Hz ({min_note})")
        st.write(f"ìµœëŒ€ ìŒì—­: {max_pitch:.2f} Hz ({max_note})")
        st.write(f"í‰ê·  ìŒì—­: {mean_pitch:.2f} Hz ({mean_note})")

        # ì‹œê°ì  ê²°ê³¼
        st.subheader("ğŸ“Š ì‹œê°ì  ê²°ê³¼")
        fig, ax = plt.subplots()
        librosa.display.waveshow(reduced_noise, sr=sr, ax=ax)
        ax.set(title="ìŒëŸ‰ ì¡°ì • ë° ë…¸ì´ì¦ˆ ì œê±°ëœ ìŒì„± íŒŒí˜•")
        st.pyplot(fig)

        st.success("ğŸ‰ ë¶„ì„ ë° ê°œì„  ì‚¬í•­ ì œì•ˆì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")